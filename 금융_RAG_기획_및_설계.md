# RAG 기반 QA 시스템 개발 계획서

## 목차
1.  [프로젝트 개요](#1-프로젝트-개요-)
2.  [전체 아키텍처](#2-전체-아키텍처-)
3.  [상세 DB 설계 (ChromaDB)](#3-상세-db-설계-chromadb-)
4.  [데이터 처리 및 인덱싱 과정](#4-데이터-처리-및-인덱싱-과정-)
5.  [하이브리드 검색 및 답변 생성](#5-하이브리드-검색-및-답변-생성-)
6.  [프론트엔드 (Streamlit)](#6-프론트엔드-streamlit-)
7.  [파인만 기법 설명 서비스 (확장)](#7-파인만-기법-설명-서비스-확장-)
8.  [DevOps 및 인프라 상세](#8-devops-및-인프라-상세-)
9.  [품질관리 (평가 및 테스트)](#9-품질관리-평가-및-테스트-)

---

### 1. 프로젝트 개요 🚀

-   **목표**: 금융 보고서에 특화된 RAG 기반 QA 시스템을 개발하여, 사용자가 복잡한 보고서의 내용을 쉽게 질문하고 정확한 답변을 얻도록 지원합니다.
-   **핵심 기능**:
    -   **하이브리드 검색**: 키워드(BM25)와 의미(벡터 임베딩) 검색을 결합하여 질문의 의도를 정확히 파악.
    -   **컨텍스트 인식 답변**: 숫자, 표, 주석 등 다양한 유형의 데이터를 활용해 답변의 정확도 향상.
    -   **출처 추적**: 답변의 근거가 된 원본 문서, 섹션, 페이지, 신뢰도 점수를 제공.
    -   **다중 문서 추론**: 여러 보고서(예: 연도별, 사업/감사보고서) 간의 데이터를 비교하고 검증.

---

### 2. 전체 아키텍처 🏛️

아래 다이어그램은 시스템의 전체적인 데이터 흐름과 구성 요소를 시각적으로 보여줍니다. 


```
[Data Sources(JSON/PDF)] 
      │
      ├─ ETL(검증·정규화·중복제거) 
      │      └─ Embedding Batch(Notes) 
      │
[ChromaDB]
     │   │
     │   └──(옵션) [Elasticsearch/Meilisearch] ← 키워드 BM25
     │
[FastAPI]  ← REST API(Reports/Accounts/Notes/Search/Ask)
     │
[RAG Service] ─ Retriever(Hybrid) ─ Reranker(옵션, Cross-Encoder)
     │                     │
     │                Context Builder
     │                     │
     └─ LLM(Answerer) ← Prompt+가드레일
            │
         JSON 응답(Answer, Sources, Context)
            │
        [Frontend(Streamlit)]
```

---

### 3. 상세 DB 설계 (ChromaDB) 💾

`ChromaDB`는 전통적인 관계형 데이터베이스와 달리 **단일 컬렉션**에 모든 데이터를 저장합니다. `PostgreSQL`의 테이블과 `JOIN` 대신, `documents`, `embeddings`, `metadatas`라는 세 가지 핵심 구성 요소를 활용합니다.

**ChromaDB의 데이터 구성 요소:**
-   **`documents`**: AI가 답변을 생성할 때 참고할 원본 텍스트 조각(청크).
-   **`embeddings`**: `documents`의 의미를 숫자로 표현한 벡터.
-   **`metadatas`**: 각 `documents`에 대한 구조화된 정보. 관계형 DB의 테이블 컬럼과 같은 역할을 수행합니다.

<br>


#### 상세 메타데이터 스키마 설계 📑

아래 표는 `PostgreSQL` 대신 `ChromaDB`의 단일 **메타데이터** 스키마로 통합한 것입니다. 모든 정보가 하나의 컬렉션에 저장되므로 검색과 관리가 훨씬 간결해집니다.

| 필드명 | 데이터 타입 | 설명 | 목적 |
|---|---|---|---|
| **`report_id`** | 문자열 | 보고서의 고유 식별자 (예: `samsung_2024_auditor`) | 특정 보고서 내에서 검색 범위를 제한하는 필터 키. |
| **`file_name`** | 문자열 | 원본 문서 파일명 (예: `감사보고서_2024.htm`) | 사용자가 문서 출처를 명확히 식별하는 데 도움. |
| **`report_type`** | 문자열 | 보고서 종류 (`사업`, `감사` 등) | 다중 문서 추론 시 특정 종류만 검색하는 필터로 활용. |
| **`company`** | 문자열 | 회사명 (예: `삼성전자`) | 특정 회사에 대한 질의에만 응답하도록 검색을 제한. |
| **`year`** | 정수 | 보고서 발행 연도 | 연도별 데이터 비교 및 시계열 질의 처리. |
| **`page_number`** | 정수 | 원본 문서의 페이지 번호 | 답변 생성 시 출처를 정확하게 추적하고 표시하는 핵심 정보. |
| **`section_path`** | 문자열 | 문서 내 계층적 경로 (`"1. 개요 > 1.1 사업의 내용"`) | `where` 필터링으로 특정 섹션 내에서만 검색하는 데 사용. |
| **`content_type`** | 문자열 | 청크의 유형 (`paragraph`, `table`, `account`) | 일반 문단, 표 데이터, 재무 계정 등 데이터 유형에 따라 검색 및 답변 전략을 다르게 적용. |
| **`title`** | 문자열 | 청크가 속한 가장 가까운 제목 | LLM에게 더 풍부한 문맥 정보 제공. |

---

### 4. 데이터 처리 및 인덱싱 과정 📊

이 단계는 복잡한 문서들을 AI가 이해할 수 있는 작은 조각들로 만들고, 효율적으로 검색할 수 있도록 저장하는 과정입니다.

-   **ETL (추출, 변환, 적재)**:
    -   **추출**: HTML, PDF, JSON 등 원본 문서에서 텍스트와 표를 추출합니다. 복잡한 HTML 구조도 `BeautifulSoup` 같은 도구를 사용해 깨끗한 텍스트로 정제합니다.
    -   **변환**: 추출된 데이터를 AI 모델이 이해하기 쉽도록 정규화합니다. 특히, 표 데이터는 **Markdown 형식으로 변환**하여 텍스트 청크에 포함시킵니다.
    -   **청크 분할**: 긴 문서를 의미적으로 관련된 작은 조각(청크)으로 나눕니다. 이 과정은 문서의 목차, 제목, 문단 구분 등을 활용하며, 이는 검색 정확도에 직접적인 영향을 미칩니다.
-   **임베딩 및 인덱싱**:
    -   **벡터화**: 각 청크는 `SentenceTransformer` 모델을 통해 수백 차원의 숫자 벡터로 변환됩니다. 이 벡터는 청크의 의미를 수학적으로 표현한 것입니다.
    -   **ChromaDB 저장**: 변환된 벡터와 함께 원본 텍스트, 그리고 **페이지 번호, 섹션 제목, 문서 경로**와 같은 메타데이터를 `ChromaDB`에 저장합니다. 이 메타데이터는 단순한 정보 이상의 역할을 하며, **검색 필터**로 활용되어 검색 범위를 좁히는 데 사용됩니다.


---

### 5. 하이브리드 검색 및 답변 생성 🔍

사용자의 질문을 이해하고 가장 적절한 답변을 찾아내는 핵심 과정입니다. 이 단계는 **단순한 키워드 매칭을 넘어 질문의 의도까지 파악**합니다.

-   **하이브리드 검색**:
    1.  **벡터 검색**: 사용자의 질문을 벡터로 변환한 후, `ChromaDB`에 저장된 청크 벡터들과의 **의미적 유사도**를 기준으로 가장 가까운 상위 N개의 청크를 찾아냅니다. 이는 '현금성 자산'이라는 질문에 '현금 및 현금성 자산'이라는 용어가 있는 문서를 찾아주는 능력입니다.
    2.  **키워드 검색**: 질문에 포함된 특정 키워드(예: '2024년', '매출액')를 활용하여 정확하게 일치하는 문서를 찾습니다.
    3.  **랭킹 융합**: 두 검색 결과는 **`RRF(Reciprocal Rank Fusion)`** 알고리즘으로 결합됩니다. 이 알고리즘은 두 검색 방식에서 모두 높은 순위를 차지한 문서를 최종 결과로 우선 선택하여 정확도를 극대화합니다.

-   **컨텍스트 빌딩 및 LLM 호출**:
    -   융합된 검색 결과를 기반으로 LLM에 제공할 **최적의 컨텍스트**를 만듭니다. 이 컨텍스트에는 검색된 청크의 원문 텍스트, 출처 메타데이터, 그리고 필요한 경우 인접한 문맥(예: 앞뒤 문단)이 포함됩니다.
    -   LLM에 **안전장치(Guardrails)**가 포함된 프롬프트를 전달합니다. 이 프롬프트는 "제공된 컨텍스트 밖의 정보를 생성하지 마세요", "모든 답변에는 출처를 명시하세요"와 같은 구체적인 지침을 포함합니다.

---

### 6. 프론트엔드 (Streamlit) 🖼️

사용자 인터페이스는 **Streamlit**을 활용하여 개발합니다.

-   **주요 UI 컴포넌트**:
    -   `st.text_input`: 사용자의 질문을 입력받는 검색창.
    -   `st.button`: 질문을 백엔드 API로 전송하는 버튼.
    -   `st.spinner`: 답변을 생성하는 동안 사용자에게 대기 상태를 표시.
    -   `st.markdown`: 답변 텍스트를 표시합니다. Markdown 문법을 지원하여 텍스트 강조나 리스트, 표를 쉽게 꾸밀 수 있습니다.
    -   `st.expander`: "참조 출처 보기"와 같이 펼치고 접을 수 있는 섹션을 만들어 UI를 깔끔하게 유지합니다.
    -   `st.bar_chart` / `st.line_chart`: 연도별 재무 데이터나 수치 비교 결과를 시각적으로 보여줍니다.

-   **사용자 플로우**:
    1.  사용자가 검색창에 질문을 입력하고 `Enter` 키를 누르거나 버튼을 클릭합니다.
    2.  Streamlit 앱은 입력된 질문을 **FastAPI** 백엔드 API에 비동기적으로 전송합니다.
    3.  API에서 받은 JSON 응답을 파싱하여, 답변 텍스트, 출처 목록, 그리고 수치 데이터를 화면에 적절한 UI 컴포넌트로 뿌려줍니다.

---

### 7. 파인만 기법 설명 서비스 (확장) 👨‍🏫

#### 서비스 개요
**"누구나 쉽게 보는 회계표, 재무제표"** - 복잡한 금융 정보를 일반인도 이해할 수 있도록 파인만 기법을 적용한 AI 에이전트


#### 파인만 기법 적용 방식

**핵심 원리**: "개념을 완벽하게 설명할 수 없으면 개념을 진정으로 이해한게 아니다"

**MVP AI 에이전트 프로세스**:

1. **주제 선택 및 학습**
   - 삼성전자 재무제표의 핵심 항목(현금및현금성자산, 매출총이익, 자산총계 등) 선택
   - 해당 항목에 대한 전문적 정의, 계산 방법, 비즈니스 의미 학습

2. **초보자 대상 설명 생성**
   - 전문 용어를 일상 언어로 변환
   - 복잡한 개념을 기본 구성 요소로 세분화
   - 간단한 유추와 실제 사례 활용

3. **수동 피드백 수집 및 분석**
   - 개발팀이 설명의 명확성과 이해도 평가 (1-5점)
   - 개선 요청사항 텍스트 코멘트 수집
   - **수동 분석**: 개발팀이 피드백을 직접 분석하고 개선점 도출

4. **수동 개선**
   - 피드백을 바탕으로 프롬프트 수정
   - 설명 템플릿 개선
   - 새로운 유추와 사례 추가

#### MVP 예시: 현금및현금성자산 설명

**초보자용 (MVP)**:
> "현금및현금성자산은 회사가 당장 쓸 수 있는 돈입니다. 마치 여러분의 지갑과 통장에 있는 돈과 같아요. 삼성전자가 2024년에 가지고 있는 현금은 약 62조원인데, 이는 서울시 예산의 3배 정도입니다. 이 돈으로 급여를 주고, 공장을 짓고, 새로운 기술을 개발할 수 있어요."

#### MVP 성공 지표

- **이해도**: 개발팀 피드백 점수 평균 3.5 이상
- **접근성**: 전문 용어 사용률 20% 이하 (MVP 목표)
- **유용성**: "도움이 되었다" 응답률 70% 이상
- **개선**: 월 1회 피드백 분석 및 설명 개선


---

### 8. DevOps 및 인프라 상세 🐳

-   **Docker Compose**:
    -   `chromadb`: 독립적인 서비스로 실행하여 `fastapi`와 분리합니다.
    -   `fastapi`: `chromadb`에 의존성을 가집니다.
    -   `redis`: 캐싱 레이어로 추가하여 동일한 쿼리 요청에 빠르게 응답합니다.
    -   `streamlit`: FastAPI와 독립적인 서비스로 실행되며, API 호출로 백엔드와 통신합니다.
-   **CI/CD**: `GitHub Actions`를 사용하여 커밋 시 테스트를 실행하고, `main` 브랜치에 병합되면 Docker 이미지를 빌드하고 배포합니다.
-   **모니터링**:
    -   **애플리케이션**: `FastAPI`의 `Prometheus` 미들웨어로 API 요청 수, 응답 시간, 에러율을 수집합니다.
    -   **LLM**: 외부 API 호출(예: OpenAI)의 지연 시간과 비용을 모니터링합니다.
    -   **시스템**: Docker 컨테이너의 CPU, 메모리, 디스크 사용량을 추적합니다.

---

### 9. 품질관리 (평가 및 테스트) ✅

-   **정확도 지표**:
    -   **수치 질문**: "2024년 순이익은 얼마인가?"와 같은 질문에 대해 답변의 오차율을 측정합니다.
    -   **사실성 (Faithfulness)**: 답변의 내용이 제공된 컨텍스트에 얼마나 정확하게 근거하는지 평가.
-   **테스트 자동화**:
    -   **단위 테스트**: ETL 파싱 함수, 하이브리드 랭킹 함수 등 개별 모듈의 기능을 검증.
    -   **통합 테스트**: `/ask` API 엔드포인트에 실제 질문을 보내고, 답변의 `answer`, `sources`, `context` 필드가 예상대로 채워졌는지 확인.


---

